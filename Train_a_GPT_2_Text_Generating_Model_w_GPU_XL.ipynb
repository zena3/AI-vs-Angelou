{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of Train a GPT-2 Text-Generating Model w/ GPU - XL model",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7LoMj4GA4n_"
      },
      "source": [
        "#  Train a GPT-2 Text-Generating Model to write poetry. \n",
        "#### \"Artificial intelligence versus Maya Angelou: Experimental evidence that people cannot differentiate AI-generated from human-written poetry\" \n",
        "\n",
        "Article llink: https://www.sciencedirect.com/science/article/pii/S0747563220303034\n",
        "\n",
        "by [Max Woolf](http://minimaxir.com) & edited by Luca Mossink\n",
        "\n",
        "*Last updated: April 24th, 2020*\n",
        "\n",
        "In the original Jupyter notebook you could retrain an advanced text generating neural network on any text dataset`gpt-2-simple`.\n",
        "\n",
        "For more about `gpt-2-simple`, you can visit [this GitHub repository](https://github.com/minimaxir/gpt-2-simple). You can also read his [blog post](https://minimaxir.com/2019/09/howto-gpt2/) for more information how to use this notebook!\n",
        "\n",
        "This notebook was run on Google Colab.\n",
        "To get started:\n",
        "\n",
        "1. Copy this notebook to your Google Drive to keep it and save your changes(File -> Save a Copy in Drive).\n",
        "2. Make sure your hardware accelerator is set to GPU. If you want to train the full model, it is advised to use a more powerful GPU. For the experiment, Köbis & Mossink used a Tesla V100.\n",
        "3. Run the cells below:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_BbNMvEaa_g"
      },
      "source": [
        "import sys \n",
        "!{sys.executable} -m pip install tensorflow==1.15.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBkpRgBCBS2_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "b7c14400-3bfb-4b14-f1cf-3f5d53b06e5e"
      },
      "source": [
        "!pip install -q gpt-2-simple\n",
        "import gpt_2_simple as gpt2\n",
        "from datetime import datetime\n",
        "#from google.colab import files"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bj2IJLHP3KwE"
      },
      "source": [
        "## GPU\n",
        "\n",
        "You may run this notebook Colaboratory uses either a Nvidia T4 GPU or an Nvidia K80 GPU. The T4 is slightly faster than the old K80 for training GPT-2, and has more memory allowing you to train the larger GPT-2 models and generate more text.\n",
        "\n",
        "You can verify which GPU is active by running the cell below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUmTooTW3osf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "1e5d1233-9edf-4024-a515-e13660d5c99e"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Apr 13 16:14:57 2020       \r\n",
            "+-----------------------------------------------------------------------------+\r\n",
            "| NVIDIA-SMI 418.87.01    Driver Version: 418.87.01    CUDA Version: 10.1     |\r\n",
            "|-------------------------------+----------------------+----------------------+\r\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P0    48W / 300W |      0MiB / 16130MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "|   1  Tesla V100-SXM2...  Off  | 00000000:00:05.0 Off |                    0 |\n",
            "| N/A   34C    P0    46W / 300W |      0MiB / 16130MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wXB05bPDYxS"
      },
      "source": [
        "## Downloading GPT-2\n",
        "\n",
        "First, you need to download the GPT-2 model you want to use. \n",
        "\n",
        "There are three released sizes of GPT-2:\n",
        "\n",
        "* `124M` (default): the \"small\" model, 500MB on disk.\n",
        "* `355M`: the \"medium\" model, 1.5GB on disk.\n",
        "* `774M`: the \"large\" model, cannot currently be finetuned with Colaboratory but can be used to generate text from the pretrained model (see later in Notebook)\n",
        "* `1558M`: the \"extra large\", true model. Will not work if a K80 GPU is attached to the notebook. (like `774M`, it cannot be finetuned).\n",
        "\n",
        "Larger models have more knowledge, but take longer to finetune and longer to generate text. You can specify which base model to use by changing `model_name` in the cells below.\n",
        "\n",
        "The next cell downloads it from Google Cloud Storage and saves it in the Colaboratory VM at `/models/<model_name>`.\n",
        "\n",
        "This model isn't permanently saved in the Colaboratory VM; you'll have to redownload it if you want to retrain it at a later time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8wSlgXoDPCR"
      },
      "source": [
        "gpt2.download_gpt2(model_name=\"774M\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgfZKP2kc9W1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "eb17002f-3e1f-49df-a7c1-a3674bc46e7a"
      },
      "source": [
        "gpt2.download_gpt2(model_name=\"1558M\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fetching checkpoint: 1.05Mit [00:00, 531Mit/s]                                                      \n",
            "Fetching encoder.json: 1.05Mit [00:00, 96.4Mit/s]                                                   \n",
            "Fetching hparams.json: 1.05Mit [00:00, 1.16Git/s]                                                   \n",
            "Fetching model.ckpt.data-00000-of-00001: 6.23Git [01:24, 73.4Mit/s]                                 \n",
            "Fetching model.ckpt.index: 1.05Mit [00:00, 733Mit/s]                                                \n",
            "Fetching model.ckpt.meta: 2.10Mit [00:00, 116Mit/s]                                                 \n",
            "Fetching vocab.bpe: 1.05Mit [00:00, 119Mit/s]                                                       \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8KXuKWzQSsN"
      },
      "source": [
        "## Mounting Google Drive\n",
        "\n",
        "The best way to get input text to-be-trained into the Colaboratory VM, and to get the trained model *out* of Colaboratory, is to route it through Google Drive *first*.\n",
        "\n",
        "Running this cell (which will only work in Colaboratory) will mount your personal Google Drive in the VM, which later cells can use to get data in/out. (it will ask for an auth code; that auth is not saved anywhere)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puq4iC6vUAHc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "eebbbb13-349d-4e01-b04b-f2968b7bc5ef"
      },
      "source": [
        "gpt2.mount_gdrive()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BT__brhBCvJu"
      },
      "source": [
        "## Uploading a Text File to be Trained to Colaboratory\n",
        "\n",
        "In the Colaboratory Notebook sidebar on the left of the screen, select *Files*. From there you can upload files:\n",
        "\n",
        "![alt text](https://i.imgur.com/TGcZT4h.png)\n",
        "\n",
        "Upload **any smaller text file**  (<10 MB) and update the file name in the cell below, then run the cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OFnPCLADfll"
      },
      "source": [
        "file_name = \"training_data_poem12.txt\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeeSKtNWUedE"
      },
      "source": [
        "If your text file is larger than 10MB, it is recommended to upload that file to Google Drive first, then copy that file from Google Drive to the Colaboratory VM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Z6okFD8VKtS"
      },
      "source": [
        "gpt2.copy_file_from_gdrive(file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdpZQXknFNY3"
      },
      "source": [
        "## Finetune GPT-2\n",
        "\n",
        "The next cell will start the actual finetuning of GPT-2. It creates a persistent TensorFlow session which stores the training config, then runs the training for the specified number of `steps`. (to have the finetuning run indefinitely, set `steps = -1`)\n",
        "\n",
        "The model checkpoints will be saved in `/checkpoint/run1` by default. The checkpoints are saved every 500 steps (can be changed) and when the cell is stopped.\n",
        "\n",
        "The training might time out after 4ish hours; make sure you end training and save the results so you don't lose them!\n",
        "\n",
        "**IMPORTANT NOTE:** If you want to rerun this cell, **restart the VM first** (Runtime -> Restart Runtime). You will need to rerun imports but not recopy files.\n",
        "\n",
        "Other optional-but-helpful parameters for `gpt2.finetune`:\n",
        "\n",
        "\n",
        "*  **`restore_from`**: Set to `fresh` to start training from the base GPT-2, or set to `latest` to restart training from an existing checkpoint.\n",
        "* **`sample_every`**: Number of steps to print example output\n",
        "* **`print_every`**: Number of steps to print training progress.\n",
        "* **`learning_rate`**:  Learning rate for the training. (default `1e-4`, can lower to `1e-5` if you have <1MB input data)\n",
        "*  **`run_name`**: subfolder within `checkpoint` to save the model. This is useful if you want to work with multiple models (will also need to specify  `run_name` when loading the model)\n",
        "* **`overwrite`**: Set to `True` if you want to continue finetuning an existing model (w/ `restore_from='latest'`) without creating duplicate copies. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeXshJM-Cuaf"
      },
      "source": [
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "gpt2.finetune(sess,\n",
        "              dataset=file_name,\n",
        "              model_name='1558M',\n",
        "              steps=1000,\n",
        "              restore_from='fresh',\n",
        "              run_name='run1',\n",
        "              print_every=10,\n",
        "              sample_every=2000,\n",
        "              save_every=1000\n",
        "              )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9v97u2MMk2zI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "646ba22d-db0f-478d-ed24-5cbc44778db0"
      },
      "source": [
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "gpt2.finetune(sess,\n",
        "              dataset=file_name,\n",
        "              model_name='1558M',\n",
        "              steps=2500,\n",
        "              restore_from='latest',\n",
        "              overwrite='True',\n",
        "              run_name='run1',\n",
        "              print_every=10,\n",
        "              sample_every=2500,\n",
        "              save_every=2500\n",
        "              )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /home/lucamossink/.local/lib/python3.5/site-packages/gpt_2_simple/src/sample.py:17: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /home/lucamossink/.local/lib/python3.5/site-packages/gpt_2_simple/src/memory_saving_gradients.py:62: get_backward_walk_ops (from tensorflow.contrib.graph_editor.select) is deprecated and will be removed after 2019-06-06.\n",
            "Instructions for updating:\n",
            "Please use tensorflow.python.ops.op_selector.get_backward_walk_ops.\n",
            "Loading checkpoint checkpoint/run1/model-1281\n",
            "INFO:tensorflow:Restoring parameters from checkpoint/run1/model-1281\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading dataset...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r100%|██████████| 1/1 [00:03<00:00,  3.44s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dataset has 575706 tokens\n",
            "Training...\n",
            "Saving checkpoint/run1/model-1281\n",
            "[1290 | 378.20] loss=1.36 avg=1.36\n",
            "[1300 | 744.07] loss=2.67 avg=2.02\n",
            "[1310 | 1111.92] loss=1.99 avg=2.01\n",
            "[1320 | 1477.36] loss=1.28 avg=1.82\n",
            "[1330 | 1844.53] loss=0.58 avg=1.57\n",
            "[1340 | 2212.34] loss=4.14 avg=2.01\n",
            "[1350 | 2582.46] loss=0.85 avg=1.84\n",
            "[1360 | 2951.68] loss=0.77 avg=1.70\n",
            "[1370 | 3322.51] loss=0.41 avg=1.55\n",
            "[1380 | 3693.94] loss=0.46 avg=1.44\n",
            "[1390 | 4067.96] loss=3.14 avg=1.60\n",
            "[1400 | 4444.90] loss=0.15 avg=1.47\n",
            "[1410 | 4821.79] loss=1.09 avg=1.44\n",
            "[1420 | 5196.94] loss=0.91 avg=1.40\n",
            "[1430 | 5571.90] loss=0.78 avg=1.36\n",
            "[1440 | 5949.34] loss=0.18 avg=1.28\n",
            "[1450 | 6327.16] loss=0.62 avg=1.24\n",
            "[1460 | 6702.32] loss=0.83 avg=1.21\n",
            "[1470 | 7079.60] loss=3.56 avg=1.35\n",
            "[1480 | 7454.59] loss=0.40 avg=1.29\n",
            "[1490 | 7830.41] loss=0.41 avg=1.25\n",
            "[1500 | 8208.09] loss=0.30 avg=1.20\n",
            "[1510 | 8584.19] loss=0.33 avg=1.16\n",
            "[1520 | 8959.63] loss=1.75 avg=1.19\n",
            "[1530 | 9336.34] loss=2.75 avg=1.26\n",
            "[1540 | 9711.01] loss=0.49 avg=1.22\n",
            "[1550 | 10086.00] loss=0.50 avg=1.19\n",
            "[1560 | 10462.55] loss=0.34 avg=1.16\n",
            "[1570 | 10837.29] loss=0.31 avg=1.12\n",
            "[1580 | 11211.34] loss=0.26 avg=1.09\n",
            "[1590 | 11584.46] loss=4.36 avg=1.21\n",
            "[1600 | 11959.82] loss=0.25 avg=1.18\n",
            "[1610 | 12332.98] loss=3.56 avg=1.26\n",
            "[1620 | 12706.36] loss=0.33 avg=1.23\n",
            "[1630 | 13079.87] loss=0.22 avg=1.20\n",
            "[1640 | 13453.72] loss=0.17 avg=1.16\n",
            "[1650 | 13824.20] loss=2.32 avg=1.20\n",
            "[1660 | 14194.20] loss=0.41 avg=1.17\n",
            "[1670 | 14565.02] loss=0.63 avg=1.16\n",
            "[1680 | 14940.11] loss=0.13 avg=1.13\n",
            "[1690 | 15316.97] loss=0.11 avg=1.10\n",
            "[1700 | 15688.55] loss=0.32 avg=1.07\n",
            "[1710 | 16059.70] loss=0.35 avg=1.05\n",
            "[1720 | 16434.49] loss=0.75 avg=1.04\n",
            "[1730 | 16806.41] loss=0.57 avg=1.03\n",
            "[1740 | 17177.88] loss=0.34 avg=1.01\n",
            "[1750 | 17549.96] loss=0.25 avg=0.99\n",
            "[1760 | 17924.34] loss=0.82 avg=0.99\n",
            "[1770 | 18300.32] loss=1.74 avg=1.01\n",
            "[1780 | 18675.94] loss=1.65 avg=1.02\n",
            "[1790 | 19053.21] loss=0.95 avg=1.02\n",
            "[1800 | 19430.45] loss=0.15 avg=1.00\n",
            "[1810 | 19808.65] loss=0.34 avg=0.98\n",
            "[1820 | 20184.59] loss=0.55 avg=0.97\n",
            "interrupted\n",
            "Saving checkpoint/run1/model-1823\n",
            "WARNING:tensorflow:From /home/lucamossink/.local/lib/python3.5/site-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXSuTNERaw6K"
      },
      "source": [
        "After the model is trained, you can copy the checkpoint folder to your own Google Drive.\n",
        "\n",
        "If you want to download it to your personal computer, it's strongly recommended you copy it there first, then download from Google Drive. The checkpoint folder is copied as a `.rar` compressed file; you can download it and uncompress it locally."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHdTL8NDbAh3"
      },
      "source": [
        "gpt2.copy_checkpoint_to_gdrive(run_name='run1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQJgV_b4bmzd"
      },
      "source": [
        "You're done! Feel free to go to the **Generate Text From The Trained Model** section to generate text based on your retrained model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pel-uBULXO2L"
      },
      "source": [
        "## Load a Trained Model Checkpoint\n",
        "\n",
        "Running the next cell will copy the `.rar` checkpoint file from your Google Drive into the Colaboratory VM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCcx5u7sbPTD"
      },
      "source": [
        "gpt2.copy_checkpoint_from_gdrive(run_name='run1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTa6zf3e_9gV"
      },
      "source": [
        "The next cell will allow you to load the retrained model checkpoint + metadata necessary to generate text.\n",
        "\n",
        "**IMPORTANT NOTE:** If you want to rerun this cell, **restart the VM first** (Runtime -> Restart Runtime). You will need to rerun imports but not recopy files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fxL77nvAMAX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "15e7497a-94ef-4a78-89b4-57a2d96e9b06"
      },
      "source": [
        "sess = gpt2.start_tf_sess()\n",
        "gpt2.load_gpt2(sess, run_name='run1')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading checkpoint checkpoint/run1/model-1823\n",
            "INFO:tensorflow:Restoring parameters from checkpoint/run1/model-1823\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClJwpF_ACONp"
      },
      "source": [
        "## Generate Text From The Trained Model\n",
        "\n",
        "After you've trained the model or loaded a retrained model from checkpoint, you can now generate text. `generate` generates a single text from the loaded model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RNY6RBI9LmL"
      },
      "source": [
        "gpt2.generate(sess, run_name='run1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oF4-PqF0Fl7R"
      },
      "source": [
        "If you're creating an API based on your model and need to pass the generated text elsewhere, you can do `text = gpt2.generate(sess, return_as_list=True)[0]`\n",
        "\n",
        "You can also pass in a `prefix` to the generate function to force the text to start with a given character sequence and generate text from there (good if you add an indicator when the text starts).\n",
        "\n",
        "You can also generate multiple texts at a time by specifing `nsamples`. Unique to GPT-2, you can pass a `batch_size` to generate multiple samples in parallel, giving a massive speedup (in Colaboratory, set a maximum of 20 for `batch_size`).\n",
        "\n",
        "Other optional-but-helpful parameters for `gpt2.generate` and friends:\n",
        "\n",
        "*  **`length`**: Number of tokens to generate (default 1023, the maximum)\n",
        "* **`temperature`**: The higher the temperature, the crazier the text (default 0.7, recommended to keep between 0.7 and 1.0)\n",
        "* **`top_k`**: Limits the generated guesses to the top *k* guesses (default 0 which disables the behavior; if the generated output is super crazy, you may want to set `top_k=40`)\n",
        "* **`top_p`**: Nucleus sampling: limits the generated guesses to a cumulative probability. (gets good results on a dataset with `top_p=0.9`)\n",
        "* **`truncate`**: Truncates the input text until a given sequence, excluding that sequence (e.g. if `truncate='<|endoftext|>'`, the returned text will include everything before the first `<|endoftext|>`). It may be useful to combine this with a smaller `length` if the input texts are short.\n",
        "*  **`include_prefix`**: If using `truncate` and `include_prefix=False`, the specified `prefix` will not be included in the returned text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DKMc0fiej4N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "707cfd4f-dfcc-44b7-8406-f8379efb9bce"
      },
      "source": [
        "gpt2.generate(sess,\n",
        "              length=75,\n",
        "              temperature=0.9,\n",
        "              top_k=40,\n",
        "              top_p=0.9,\n",
        "              prefix=\"They burnt a corpse upon the sand-- The light shone out afar;\",\n",
        "              nsamples=20,\n",
        "              batch_size=10\n",
        "              )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "They burnt a corpse upon the sand-- The light shone out afar;\n",
            "                                                                          \n",
            "====================\n",
            "They burnt a corpse upon the sand-- The light shone out afar;\n",
            "                                                                          \n",
            "====================\n",
            "They burnt a corpse upon the sand-- The light shone out afar;\n",
            "                                                                          \n",
            "====================\n",
            "They burnt a corpse upon the sand-- The light shone out afar;\n",
            "And down a green plain, leaping, laughing, squealed:\n",
            "\"Ahoy! who is this laughing thing?\n",
            "  I'll give my stags, my hills and dales,\n",
            "  My stormcocks and my nightingales.\n",
            "\n",
            "\"And I'll chew up your silks,--you're dead,--\n",
            "  You'll\n",
            "====================\n",
            "They burnt a corpse upon the sand-- The light shone out afar;\n",
            "                                                                          \n",
            "====================\n",
            "They burnt a corpse upon the sand-- The light shone out afar;\n",
            "                                                                          \n",
            "====================\n",
            "They burnt a corpse upon the sand-- The light shone out afar;\n",
            "                                                                          \n",
            "====================\n",
            "They burnt a corpse upon the sand-- The light shone out afar;\n",
            "                                                                          \n",
            "====================\n",
            "They burnt a corpse upon the sand-- The light shone out afar;\n",
            "                                                                          \n",
            "====================\n",
            "They burnt a corpse upon the sand-- The light shone out afar;\n",
            "                                                                          \n",
            "====================\n",
            "They burnt a corpse upon the sand-- The light shone out afar;\n",
            "And green, dead weeds swept by on the shoulder blades,\n",
            "                                                             \n",
            "====================\n",
            "They burnt a corpse upon the sand-- The light shone out afar;\n",
            "                                                                          \n",
            "====================\n",
            "They burnt a corpse upon the sand-- The light shone out afar;\n",
            "                                                                          \n",
            "====================\n",
            "They burnt a corpse upon the sand-- The light shone out afar;\n",
            "And ships and woodsmen set about the lonely man\n",
            "With fathomless night-lights. The thick wall\n",
            "Of island estremer dims and reddens and fills\n",
            "The horizon with dust; the lone\n",
            "Invisible pulls on the sand\n",
            "And shuts the door on the sun.\n",
            " \n",
            "And very stone grows, and grave\n",
            "The lone man stands\n",
            "====================\n",
            "They burnt a corpse upon the sand-- The light shone out afar;\n",
            "                                                                          \n",
            "====================\n",
            "They burnt a corpse upon the sand-- The light shone out afar;\n",
            "  The steersman's eye was all aglow,\n",
            "  And hard upon the water-sky,\n",
            "And frigates stooped in fleets\n",
            "  To take the outline of a body\n",
            "  And send it in!\n",
            "\n",
            "  The figure of a ship\n",
            "  That struts to the shore\n",
            "And turns to the wind and leans\n",
            "  With a\n",
            "====================\n",
            "They burnt a corpse upon the sand-- The light shone out afar;\n",
            "                                                                          \n",
            "====================\n",
            "They burnt a corpse upon the sand-- The light shone out afar;\n",
            "And daylight walked by slowly\n",
            "          On the bright sand.\n",
            "\n",
            "                                                     \n",
            "====================\n",
            "They burnt a corpse upon the sand-- The light shone out afar;\n",
            "And gray ashes covered the water,\n",
            "  And a hole in the rock\n",
            "                                                          \n",
            "====================\n",
            "They burnt a corpse upon the sand-- The light shone out afar;\n",
            "                                                                          \n",
            "====================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mHB9dyXjCcF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjjEN2Tafhl2"
      },
      "source": [
        "For bulk generation, you can generate a large amount of text to a file and sort out the samples locally on your computer. The next cell will generate a generated text file with a unique timestamp.\n",
        "\n",
        "You can rerun the cells as many times as you want for even more generated texts!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxWvMiy6yZUY"
      },
      "source": [
        "gen_file = 'gpt2_gentext_{:%Y%m%d_%H%M%S}.txt'.format(datetime.utcnow())\n",
        "\n",
        "gpt2.generate_to_file(sess,\n",
        "                      destination_path=gen_file,\n",
        "                      length=100,\n",
        "                      temperature=0.9,\n",
        "                      top_k=40,\n",
        "                      nsamples=20,\n",
        "                      batch_size=10\n",
        "                      )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgYEtdVVpKpy"
      },
      "source": [
        "gen_file = 'gpt2_gentext_{:%Y%m%d_%H%M%S}.txt'.format(datetime.utcnow())\n",
        "\n",
        "gpt2.generate_to_file(sess,\n",
        "                      destination_path=gen_file,\n",
        "                      length=75,\n",
        "                      temperature=0.85,\n",
        "                      prefix=\"Everyday, I think about dying.\",\n",
        "                      top_k=40,\n",
        "                      nsamples=20,\n",
        "                      batch_size=10\n",
        "                      )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-LRex8lfv1g"
      },
      "source": [
        "# may have to run twice to get file to download\n",
        "files.download(gen_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQAN3M6RT7Kj"
      },
      "source": [
        "## Generate Text From The Pretrained Model\n",
        "\n",
        "If you want to generate text from the pretrained model, not a finetuned model, pass `model_name` to `gpt2.load_gpt2()` and `gpt2.generate()`.\n",
        "\n",
        "This is currently the only way to generate text from the 774M or 1558M models with this notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsUd_jHgUZnD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "36b7baa4-bfaa-4647-ece8-0185baa0017c"
      },
      "source": [
        "model_name = \"1558M\"\n",
        "\n",
        "gpt2.download_gpt2(model_name=model_name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fetching checkpoint: 1.05Mit [00:00, 508Mit/s]                                                      \n",
            "Fetching encoder.json: 1.05Mit [00:00, 132Mit/s]                                                    \n",
            "Fetching hparams.json: 1.05Mit [00:00, 736Mit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 6.23Git [02:07, 48.9Mit/s]                                 \n",
            "Fetching model.ckpt.index: 1.05Mit [00:00, 556Mit/s]                                                \n",
            "Fetching model.ckpt.meta: 2.10Mit [00:00, 216Mit/s]                                                 \n",
            "Fetching vocab.bpe: 1.05Mit [00:00, 238Mit/s]                                                       \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAe4NpKNUj2C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "7d50bcc7-a302-42fe-e15c-958a37bcc072"
      },
      "source": [
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "gpt2.load_gpt2(sess, model_name=model_name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading pretrained model models/1558M/model.ckpt\n",
            "INFO:tensorflow:Restoring parameters from models/1558M/model.ckpt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xInIZKaU104",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "15d099aa-c1ce-47a1-8f2a-007b3d23f448"
      },
      "source": [
        "gpt2.generate(sess,\n",
        "              model_name=model_name,\n",
        "              prefix=\"The secret of life is to take risks whenever possible\",\n",
        "              length=500,\n",
        "              temperature=0.9,\n",
        "              top_p=0.9,\n",
        "              nsamples=10,\n",
        "              batch_size=5\n",
        "              )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /home/lucamossink/.local/lib/python3.5/site-packages/gpt_2_simple/src/sample.py:32: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "The secret of life is to take risks whenever possible,\" I had told him, \"and to get comfortable with small doses of pleasure. But one should never allow anything to become a substitute for a deep conviction in what is good.\"\n",
            "\n",
            "Although he had tried to please me, Dr. Mössbauer could not find me in his list. He had gone on to a similar list of my friends and acquaintances. I turned away.\n",
            "\n",
            "In the second room, where he had also made his initial impression of me, he stopped short. I was a little surprised. He made his intentions plain enough. He was interested in what I had to say, but didn't know how to express it.\n",
            "\n",
            "I was prepared to take him under my wing. It would be only a short visit, and we could get to know one another, learn about each other's lives.\n",
            "\n",
            "But I was tired of the whole situation. He had shown no curiosity about my ideas, and the moment he had realized I didn't know them well enough to give him a good description of them, he had demanded that I tell him everything about myself, and perhaps tried to make me feel uncomfortable, because he didn't want to talk about himself. He was trying to turn me into a high priest, a siren, a seductress. I didn't have any desire for such a role, and I didn't think that Dr. Mössbauer would be able to use my frankness to manipulate me. But he was evidently satisfied, because now he was trying to create some sort of atmosphere of intimacy between us.\n",
            "\n",
            "\"I'm not interested in you,\" I said. \"I want to speak to one person about my ideas. If I can find the right person, then that will be the place for me to speak with him.\"\n",
            "\n",
            "He said that he would be glad to talk with me. He would send someone to find me a suitable person.\n",
            "\n",
            "I was in a state of tension and confusion.\n",
            "\n",
            "It was even worse when I met the person I wanted to talk with.\n",
            "\n",
            "I went to a hotel room near Dr. Mössbauer's office. I wanted to speak quietly, without being noticed, and I went alone.\n",
            "\n",
            "As I left the room, I saw him walking up and down. He was mumbling something to himself.\n",
            "\n",
            "Suddenly I realized that I had been caught up in his thought. He had forgotten my call, had forgotten\n",
            "====================\n",
            "The secret of life is to take risks whenever possible. To explore and discover your limits. To take risks in business and politics. To take risks in education and sports. To take risks in your own relationships.\n",
            "\n",
            "The secret of life is to fail fast. Sooner or later, the fear of failure, of not having enough to lose, of being unable to do it, becomes a small price to pay.\n",
            "\n",
            "The secret of life is to be greedy for the opportunity, to see the big picture. To look at the whole puzzle, to see the big picture. Not to look at the small picture.\n",
            "\n",
            "The secret of life is to have a set of values that you live by. When I speak of values, I am referring to the things that we think are important to us. The things that are part of who we are as people, and as people who live.\n",
            "\n",
            "The secret of life is to find a way to motivate yourself to do things that you know you have a passion for, that you know you'll like, that you know you'll love doing.\n",
            "\n",
            "The secret of life is to not get stuck in the rut of your own value system.\n",
            "\n",
            "The secret of life is to say, \"I love what I do.\"\n",
            "\n",
            "The secret of life is to say, \"I love what I do, and I will go after it until I get it right.\"\n",
            "\n",
            "The secret of life is to say, \"I love what I do, and I am passionate about it, and I will go after it until it gets it right.\"\n",
            "\n",
            "The secret of life is to say, \"I love what I do, and I will pursue it until I am satisfied.\"\n",
            "\n",
            "The secret of life is to say, \"I love what I do, and I am not satisfied with what I do. I want to do it better.\"\n",
            "\n",
            "The secret of life is to say, \"I love what I do, and I would love to do it better.\"\n",
            "\n",
            "The secret of life is to say, \"I love what I do, and I know I can do it better.\"\n",
            "\n",
            "The secret of life is to say, \"I love what I do, and I would love to do it better.\"\n",
            "\n",
            "The secret of life is to say, \"I love what I do, and I will do it better.\"\n",
            "\n",
            "The secret of life is to say, \"I love what I do, and I will go after\n",
            "====================\n",
            "The secret of life is to take risks whenever possible,\" Brian told an audience of the U.K. Parliament last week. The conference will help him explore these risks, he told a Dutch audience.\n",
            "\n",
            "Also see: Brian Harmer: Working with Office of U.S. Trade Representative on Japanese tariffs\n",
            "\n",
            "Brian, who is from a small town in Montana, has spent his whole life operating in the corporate world, traveling the world to do business. And while Brian has had his ups and downs, he has always found the adventure of the business world rewarding.\n",
            "\n",
            "Working with the Office of the United States Trade Representative is a new challenge for Brian. He and his colleagues are working on several trade issues, but they have a target on their backs -- for many, the TPP is the most important trade deal ever negotiated. It could be the lynchpin of America's economic future.\n",
            "\n",
            "Brian has seen firsthand the potential dangers in the current global economy and how trade is influencing our lives. He knows the importance of investing in our own people and supporting small businesses and the entrepreneurial spirit.\n",
            "\n",
            "When I asked Brian what his favorite part of the trip was so far, he told me: \"seeing the world.\"\n",
            "\n",
            "From a young age, Brian was surrounded by people who wanted him to succeed, and he was encouraged to pursue his passion for entrepreneurship. Brian found the entrepreneurial spirit in the town of Bozeman, Montana, where he graduated high school, and he still carries the ideals of that town with him today.\n",
            "\n",
            "He and his family are still interested in entrepreneurship and small businesses. Brian is also helping his mom start her own business and she is working on a second business with Brian.\n",
            "\n",
            "When Brian and his mom started their business, they had no experience running a business. Since then, they have grown their business and are creating jobs in Bozeman.\n",
            "\n",
            "Since Brian started his first business, he has put his entrepreneurial skills to use in creating job opportunities for others. He worked with a charity called Cascadia Center for the Arts in Portland, Oregon, where he founded a nonprofit organization, School Bus Ministry. He also serves on the board of directors of the National Association for the Advancement of Colored People and the Pioneer Institute.\n",
            "\n",
            "When he travels, Brian gives talks about his experiences. He speaks about the importance of entrepreneurship, and he encourages other young people to start their own businesses.\n",
            "\n",
            "I spoke with Brian about his inspiration to pursue entrepreneurship, the challenges of\n",
            "====================\n",
            "The secret of life is to take risks whenever possible and look for opportunity to utilize those opportunities,\" he says. \"That's the way I grew up and that's the way I'm still growing. To me, that's the secret. I don't know if it's the secret of life. I'm going to continue to go to work every day, and I'm going to push myself every day. That's what it's all about. You have to get out of your comfort zone.\"\n",
            "\n",
            "George, who was a family friend of MacKaye's, was inducted into the Hockey Hall of Fame in 2011.\n",
            "\n",
            "George also has a special connection to the Canada Cup.\n",
            "\n",
            "\"It's going to be something to remember for years to come,\" he said. \"It's something special to me.\"\n",
            "\n",
            "MacKaye was the captain of the 1977 Canadian men's team that won the tournament.\n",
            "\n",
            "George, who was coaching at the time, never dreamed that he would see the day when his friend, a sportswriter for the Ottawa Citizen, would be inducted into the Hockey Hall of Fame.\n",
            "\n",
            "\"I knew he was a great guy but I didn't know he was a Hall of Fame player,\" said George, who has worked as a broadcaster for TSN. \"I had no idea until I got a phone call this morning from a friend of mine and he said, 'Hey, you're not going to believe it.'\n",
            "\n",
            "\"It's absolutely a big honour. It's a dream come true. It's just a great feeling. It's one of those things that you don't really think it can happen to you. It's good timing. It's the right place and the right time.\"\n",
            "\n",
            "MacKaye was inducted into the Hockey Hall of Fame in 2015.\n",
            "\n",
            "George, who spent 30 years in the NHL, started his playing career with the Edmonton Oilers and played for the St. Louis Blues, Vancouver Canucks and Calgary Flames.<|endoftext|>Her father is in poor health and his beloved 15-year-old sister is expected to die soon. Her mother, a farmhand, needs to work for the rest of her life to provide for her three children.\n",
            "\n",
            "The sister, who was taken from her family in a bid to curb India's high levels of rape, was dumped in a forest in the tribal district of Giridih. Her body was found on Tuesday, still in her pyjamas, after villagers had reported her missing\n",
            "====================\n",
            "The secret of life is to take risks whenever possible.\n",
            "\n",
            "The secret of life is to take risks whenever possible.\n",
            "\n",
            "The secret of life is to take risks whenever possible.\n",
            "\n",
            "The secret of life is to take risks whenever possible.\n",
            "\n",
            "The secret of life is to take risks whenever possible.\n",
            "\n",
            "The secret of life is to take risks whenever possible.\n",
            "\n",
            "The secret of life is to take risks whenever possible.\n",
            "\n",
            "The secret of life is to take risks whenever possible.\n",
            "\n",
            "The secret of life is to take risks whenever possible.\n",
            "\n",
            "The secret of life is to take risks whenever possible.\n",
            "\n",
            "The secret of life is to take risks whenever possible.\n",
            "\n",
            "The secret of life is to take risks whenever possible.\n",
            "\n",
            "The secret of life is to take risks whenever possible.\n",
            "\n",
            "The secret of life is to take risks whenever possible.\n",
            "\n",
            "The secret of life is to take risks whenever possible.\n",
            "\n",
            "The secret of life is to take risks whenever possible.\n",
            "\n",
            "The secret of life is to take risks whenever possible.\n",
            "\n",
            "The secret of life is to take risks whenever possible.\n",
            "\n",
            "The secret of life is to take risks whenever possible.\n",
            "\n",
            "The secret of life is to take risks whenever possible.\n",
            "\n",
            "The secret of life is to take risks whenever possible.\n",
            "\n",
            "The secret of life is to take risks whenever possible.\n",
            "\n",
            "The secret of life is to take risks whenever possible.\n",
            "\n",
            "The secret of life is to take risks whenever possible.\n",
            "\n",
            "The secret of life is to take risks whenever possible.\n",
            "\n",
            "The secret of life is to take risks whenever possible.\n",
            "\n",
            "The secret of life is to take risks whenever possible.\n",
            "\n",
            "The secret of life is to take risks whenever possible.\n",
            "\n",
            "The secret of life is to take risks whenever possible.\n",
            "\n",
            "The secret of life is to take risks whenever possible.\n",
            "\n",
            "The secret of life is to take risks whenever possible.\n",
            "\n",
            "The secret of life is to take risks whenever possible.\n",
            "\n",
            "The secret of life is to take risks whenever possible.\n",
            "\n",
            "The secret of life is to take risks whenever possible.\n",
            "\n",
            "The secret of life is to take risks whenever possible.\n",
            "\n",
            "The secret of life is to take risks whenever possible.\n",
            "\n",
            "The secret of life is to take risks whenever possible.\n",
            "\n",
            "The secret of life is to take risks whenever possible.\n",
            "\n",
            "The secret of life is to take risks whenever possible.\n",
            "\n",
            "The secret of\n",
            "====================\n",
            "The secret of life is to take risks whenever possible\n",
            "\n",
            "One thing I can guarantee about working with my clients is that they are incredibly cool people. So when they ask me to do something, I try to fulfill their request. I don't mind saying that I do this often and not without a good reason.\n",
            "\n",
            "For example, I had to keep a man who was having sex with his ex-wife from making an unwanted \"hug\" with her. And that man was one of the most successful speakers at my conference, so I knew it would not be a \"hug.\" And he was a very attractive man. So I was confident that I could make him feel a little uncomfortable with something I could say.\n",
            "\n",
            "Later, I asked him what he was talking about with his hand. His eyes lit up as he replied, \"That was a hug!\" And I was like, \"Oh yeah? Well, then I guess I won't make you feel uncomfortable by hugging you, you understand?\" I also played a little joke on him. I said to him, \"You know, when you are hugging, the sweat can just build up and the real hot spot is right here, and right below your shoulder. It's just a hot spot. That's what the sweat is for.\"\n",
            "\n",
            "And that is why I do my best work when I feel uncomfortable. I try to go above and beyond. I am a natural speaker and I have a great deal of confidence. And that confidence is what makes me succeed.\n",
            "\n",
            "Follow this program and you will do well, no matter what your calling in life.\n",
            "\n",
            "2. Work on a Relaxed Social Schedule\n",
            "\n",
            "I would say that the main ingredient to creating a great atmosphere is the consistency of your social schedule. As you know, it is not possible to spend all of your free time hanging out with friends. In fact, people lose a lot of their energy by going out too often. They feel like they are not being listened to or that they are being talked down to.\n",
            "\n",
            "So, the key to creating an environment where you feel comfortable is to make sure you go out to lunch, you go to parties and you go out to dinner. Don't go out for lunch on Thursday because you have meetings that day. And don't go out for dinner on Friday because you have meetings that day.\n",
            "\n",
            "Socializing should not be so work-intensive that you feel like you are being pushed around. That is why I recommend working\n",
            "====================\n",
            "The secret of life is to take risks whenever possible. I'm sure that if you were a kid in the 1960s, you too had that thought, \"I wonder what it's like if I do something dangerous, and if I don't do it, somebody else will\".\n",
            "\n",
            "The secret of life is to take risks whenever possible. I'm sure that if you were a kid in the 1960s, you too had that thought, \"I wonder what it's like if I do something dangerous, and if I don't do it, somebody else will\".\n",
            "\n",
            "And so we did. I was in a boat, travelling on a river. I have an extraordinary memory of a man and a dog sitting by the side of the river and we talked for half an hour. And when we came to the end of the conversation, I was invited into the boat to have a drink. I asked him what he thought he was going to do with the water, and he said \"Oh, well, I'll probably put it into the garden, just to make a lake\", and he sat down and he looked at me with those big eyes and I said, \"Are you sure you're not going to put it in the garden and then drink the water and drown yourself?\" and he looked at me and he said, \"No\", and I said, \"Oh my God, you are!\" I didn't want to be there, but I had to go in.\n",
            "\n",
            "And it was fascinating, the fact that he was doing what he did. He was telling me something about what he thought he would do, and what he did, and the fact that he was interested in the question. And I wondered whether I was going to do the same. It was incredible, and I've been meaning to talk about it for 30 years.\n",
            "\n",
            "I would always get asked \"What do you think of the idea that there is something special about risk, or that the ocean is somehow different to any other environment, and that we should try and do it in the ocean?\" Well, it was a wonderful idea. I was so young when I heard that. And it still is. Because I have my first child, and I'm a father myself. I've always wanted to take my wife out on a boat.\n",
            "\n",
            "I would always get asked \"What do you think of the idea that there is something special about risk, or that the ocean is somehow different to any other environment, and that we should try and do\n",
            "====================\n",
            "The secret of life is to take risks whenever possible. Although you might never have to use them, your friends and family might. Be willing to take a chance and take them when they are available.\n",
            "\n",
            "While not the most common technique to create life, the mocap method is one of the most potent and effective techniques you can use to enhance your body performance. The mocap technique is basically about using a laser marker to capture the exact movements you need to make while performing certain exercises. In the beginning, mocap should be done only when it is absolutely necessary and to get used to it, you should do several sessions before practicing in front of a mirror. It is recommended to start off by using mocap during warm-ups. However, it is important to learn how to use mocap and how to use it correctly.\n",
            "\n",
            "What is Mocap?\n",
            "\n",
            "Mocap stands for \"marking with light.\" In other words, mocap is a technique that helps you to record specific movement movements that you are making during specific exercises. Mocap is performed by using a light laser pointer to illuminate the area in front of your chest. The user presses the button that fires the laser pointer and measures the return on the measurement of the laser beam. This return is measured with a surface probe (which is specifically designed to help measure the return on the light beam), the actual size of the marker, and the size of the marker to the next nearest micron. These measurements are used to calculate the exact movement that is being recorded.\n",
            "\n",
            "Mocap can be performed both static and dynamic. Static mocap is when you rest with your arms in the same position and the laser pointer is pointing at the chest. Static mocap can be used while you are lying on your back or lying on your stomach. Dynamic mocap is performed by using the laser pointer while you are performing the exercise. This is usually done while performing a very fast repetition, such as a military press or a push-up. Dynamic mocap can also be used during any other exercise where you need to be static such as squats, leg presses, or push-ups.\n",
            "\n",
            "What is the Benefits of Mocap?\n",
            "\n",
            "When using mocap, you will notice that it provides several advantages over using a body scanner. In addition to the lack of delay and the fact that it is extremely accurate, mocap provides a number of other benefits to your body performance\n",
            "====================\n",
            "The secret of life is to take risks whenever possible,\" Van der Linde says. \"It's how you operate. That is what I've learned from the Beatles, the Rolling Stones, Bob Dylan, and others, who I think have shaped me and my career.\"\n",
            "\n",
            "On his record label, he also teamed with indie pop band Adventure Club for his album, The Van Der Linde Sound, which features guest appearances by Taylor Swift, Ed Sheeran, and Karen O.\n",
            "\n",
            "\"I think it's really important for my career to continue to evolve and explore different styles,\" he says. \"I have no intention of giving up on my songwriting, which I feel very passionate about. We will continue to try out new stuff, and it's important for me to take risks.\"\n",
            "\n",
            "\"I think his name will be synonymous with that one-of-a-kind sound that he has when he's performing, and the importance of that style and his voice and his spirit will always be in our hearts and the hearts of our fans.\"\n",
            "\n",
            "As for his career, Van der Linde says he'll be fine-tuning a handful of tracks on his new album, including \"I See You,\" an homage to the late Prince that he performed live on his 30th birthday, in December.\n",
            "\n",
            "\"It's very heartfelt,\" he says. \"It's me singing an old Prince song. It's very personal. It's about my friends, and the people I've met. It's about traveling and meeting people and being in a new city and not knowing what to expect, but not knowing who you are.\"\n",
            "\n",
            "He also told Billboard that he's currently recording his first studio album, which will be out next year.\n",
            "\n",
            "\"I'm working on some new stuff and I'll probably do a follow-up to this record, too,\" he says. \"It's very different, and it's a lot of fun.\"<|endoftext|>It's about time for some more heartbreak in the world of fashion.\n",
            "\n",
            "A Japanese tourist apparently fell into the gaping maw of a giant, poisonous toad in a cave in central Japan's Kyushu region, and has been fighting for her life ever since, an official said.\n",
            "\n",
            "The man, who was in his 60s, was found by tourists who had gone to investigate what they thought was a large hole in a wall of the cave. When they came back, they found the man lying face down in the cavern floor\n",
            "====================\n",
            "The secret of life is to take risks whenever possible, and the secret of life is to sleep in the lap of nature. — Ivan Pavlov\n",
            "\n",
            "As I type these words I am walking through the woods off in the distance. A woman was standing there, curled up in a ball, peering at me from a great distance. I realized then that I had been standing there for a long time, the sun now disappearing behind the trees.\n",
            "\n",
            "As I was walking away I heard her voice, it was the sound of a cricket. She must have fallen asleep, I guess. I had to find my way back to where I had been. I continued walking in the direction of the house, which was now well hidden. I don't think I had ever walked through this place before, but I couldn't stay away. I had to keep walking. I must be prepared for anything, and the most dangerous things are those that are unexpected.\n",
            "\n",
            "After a few more minutes I heard a rustling in the bushes, so I stopped. I was shaking violently and I was sweating profusely. As I listened closely I heard the sound of a rustling in the bushes. My ears were so attuned to this sound that I could hear the rustle of clothes, and then I could hear the rustle of a woman's jacket. I was able to pick up her voice, she was asking me to come back into the house. She was a little drunk. She seemed to be in a state of severe distress. I approached the window and looked out into the clearing, which was now completely dark. It was dark because of the thick forest which was covering the trees. I could see all the way to the horizon.\n",
            "\n",
            "I stopped next to the window and peered out into the clearing. I saw nothing in the clearing. I tried to call out to her, but the tree was so thick that I couldn't get a clear call. There was a thin line of light between the branches, but I couldn't see the figure that was on the other side. I stood there, staring at the clearing, and then I heard the rustle of a woman's jacket. It was her. She was coming back. She walked right out into the light.\n",
            "\n",
            "I ran back inside, and we carried her out to the house. I could tell that she was very shaken up. I put her in the bed, and then I tried to rest her. I rolled her onto her back\n",
            "====================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ig-KVgkCDCKD"
      },
      "source": [
        "# Etcetera\n",
        "\n",
        "If the notebook has errors (e.g. GPU Sync Fail), force-kill the Colaboratory virtual machine and restart it with the command below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIHiVP53FnsX"
      },
      "source": [
        "!kill -9 -1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmTXWNUygS5E"
      },
      "source": [
        "# LICENSE\n",
        "\n",
        "MIT License\n",
        "\n",
        "Copyright (c) 2019 Max Woolf\n",
        "\n",
        "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
        "of this software and associated documentation files (the \"Software\"), to deal\n",
        "in the Software without restriction, including without limitation the rights\n",
        "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
        "copies of the Software, and to permit persons to whom the Software is\n",
        "furnished to do so, subject to the following conditions:\n",
        "\n",
        "The above copyright notice and this permission notice shall be included in all\n",
        "copies or substantial portions of the Software.\n",
        "\n",
        "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
        "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
        "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
        "SOFTWARE."
      ]
    }
  ]
}